{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50f2006b-489c-432f-996e-1a5e3cc2fa03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Feature selection plays an important role when it comes to improve outlier detection in terms of identifying noisy\\n   data that contain irrelevant or redundant features. State-of-the-art work either focuses on unsupervised feature \\n   selection for data streams or (offline) outlier detection.\\n   The anomaly detection/feature selection is done by simply flagging each metric as a zero or a 1 if its value is inside\\n   or outside normal range (0 for within normal range; 1 for outside of normal range).\\n   I also calculate a “flag ratio” that expresses how far outside of normal the value is.\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q1\n",
    "'''Feature selection plays an important role when it comes to improve outlier detection in terms of identifying noisy\n",
    "   data that contain irrelevant or redundant features. State-of-the-art work either focuses on unsupervised feature \n",
    "   selection for data streams or (offline) outlier detection.\n",
    "   The anomaly detection/feature selection is done by simply flagging each metric as a zero or a 1 if its value is inside\n",
    "   or outside normal range (0 for within normal range; 1 for outside of normal range).\n",
    "   I also calculate a “flag ratio” that expresses how far outside of normal the value is.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1b8388b-10c8-4e92-985f-dbd2c2f806ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Beyond accuracy, the most commonly used metrics when evaluating anomaly detection solutions are F1, Precision and \\n   Recall.\\n   Intuitively Measuring & Explaining Performance\\n    Recall: 6 / (6 + 9) = 0.4.\\n    Precision: 6 / (6 + 4) = 0.6.\\n    F1 Score: 2 * (0.4 * 0.6) / (0.4 + 0.6) = 0.48.\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q2\n",
    "'''Beyond accuracy, the most commonly used metrics when evaluating anomaly detection solutions are F1, Precision and \n",
    "   Recall.\n",
    "   Intuitively Measuring & Explaining Performance\n",
    "    Recall: 6 / (6 + 9) = 0.4.\n",
    "    Precision: 6 / (6 + 4) = 0.6.\n",
    "    F1 Score: 2 * (0.4 * 0.6) / (0.4 + 0.6) = 0.48.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7cb2d2a-a714-4196-a362-937666140eae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"DBSCAN is a density-based clustering algorithm that works on the assumption that clusters are dense regions in space\\n   separated by regions of lower density. It groups 'densely grouped' data points into a single cluster.\\n   the DBSCAN algorithm\\n1. Classify the points.\\n2. Discard noise.\\n3. Assign cluster to a core point.\\n4. Color all the density connected points of a core point.\\n5. Color boundary points according to the nearest core point.\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q3\n",
    "'''DBSCAN is a density-based clustering algorithm that works on the assumption that clusters are dense regions in space\n",
    "   separated by regions of lower density. It groups 'densely grouped' data points into a single cluster.\n",
    "   the DBSCAN algorithm\n",
    "1. Classify the points.\n",
    "2. Discard noise.\n",
    "3. Assign cluster to a core point.\n",
    "4. Color all the density connected points of a core point.\n",
    "5. Color boundary points according to the nearest core point.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7a00344-eeee-4e5d-8c83-89b490fccff1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In other words, it is the distance that DBSCAN uses to determine if two points are similar and belong together. A\\n   larger epsilon will produce broader clusters (encompassing more data points) and a smaller epsilon will build smaller\\n   clusters.\\n   Too small epsilon: If epsilon is chosen much too small, then a large part of the data will not be clustered. Too large\\n   epsilon: If epsilon is chosen much too large, then clusters will merge and the majority of objects will be in the same\\n   cluster.\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q4\n",
    "'''In other words, it is the distance that DBSCAN uses to determine if two points are similar and belong together. A\n",
    "   larger epsilon will produce broader clusters (encompassing more data points) and a smaller epsilon will build smaller\n",
    "   clusters.\n",
    "   Too small epsilon: If epsilon is chosen much too small, then a large part of the data will not be clustered. Too large\n",
    "   epsilon: If epsilon is chosen much too large, then clusters will merge and the majority of objects will be in the same\n",
    "   cluster.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "615fb75a-7992-42e1-8f32-6c8f1f981fe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Core — This is a point that has at least m points within distance n from itself. Border — This is a point that has at\\n   least one Core point at a distance n. Noise — This is a point that is neither a Core nor a Border. And it has less\\n   than m points within distance n from itself.\\n   The Core Points, as the name suggests, lie usually within the interior of a cluster. A Border Point has fewer than \\n   MinPts within its ϵ-neighborhood (N), but it lies in the neighborhood of another core point. Noise is any data point\\n   that is neither core nor border point.\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q5\n",
    "'''Core — This is a point that has at least m points within distance n from itself. Border — This is a point that has at\n",
    "   least one Core point at a distance n. Noise — This is a point that is neither a Core nor a Border. And it has less\n",
    "   than m points within distance n from itself.\n",
    "   The Core Points, as the name suggests, lie usually within the interior of a cluster. A Border Point has fewer than \n",
    "   MinPts within its ϵ-neighborhood (N), but it lies in the neighborhood of another core point. Noise is any data point\n",
    "   that is neither core nor border point.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "471844b2-8e8b-40f7-9932-536f0e754245",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This algorithm can be used out of the box for fraud detection in only a few simple steps.\\nStep 1: Import libraries. For this demo, we need three key libraries for data wrangling, visualization and modeling. ...\\nStep 2: Import & visualize data. \\nStep 3: Modeling. \\nStep 4: Visualizing. \\nStep 5: Creating an outliers data frame.\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q6\n",
    "'''This algorithm can be used out of the box for fraud detection in only a few simple steps.\n",
    "Step 1: Import libraries. For this demo, we need three key libraries for data wrangling, visualization and modeling. ...\n",
    "Step 2: Import & visualize data. \n",
    "Step 3: Modeling. \n",
    "Step 4: Visualizing. \n",
    "Step 5: Creating an outliers data frame.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2555f6e-094c-41b3-9ed8-9d99b6a2feeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Make a large circle containing a smaller circle in 2d. A simple toy dataset to visualize clustering and classification\\n   algorithms.\\n   The make_blobs() function can be used to generate blobs of points with a Gaussian distribution. You can control how3\\n   many blobs to generate and the number of samples to generate, as well as a host of other properties.\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q7\n",
    "'''Make a large circle containing a smaller circle in 2d. A simple toy dataset to visualize clustering and classification\n",
    "   algorithms.\n",
    "   The make_blobs() function can be used to generate blobs of points with a Gaussian distribution. You can control how3\n",
    "   many blobs to generate and the number of samples to generate, as well as a host of other properties.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "191f0fa6-746a-42ab-a66a-175b9c39b7b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'There are two general types of outlier detection: global and local. Global outliers fall outside the normal range for\\n   an entire dataset, whereas local outliers may fall within the normal range for the entire dataset, but outside the\\n   normal range for the surrounding data points.\\n   A global outlier is a measured sample point that has a very high or a very low value relative to all the values in a \\n   dataset. For example, if 99 out of 100 points have values between 300 and 400, but the 100th point has a value of 750,\\n   the 100th point may be a global outlier.\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q8\n",
    "'''There are two general types of outlier detection: global and local. Global outliers fall outside the normal range for\n",
    "   an entire dataset, whereas local outliers may fall within the normal range for the entire dataset, but outside the\n",
    "   normal range for the surrounding data points.\n",
    "   A global outlier is a measured sample point that has a very high or a very low value relative to all the values in a \n",
    "   dataset. For example, if 99 out of 100 points have values between 300 and 400, but the 100th point has a value of 750,\n",
    "   the 100th point may be a global outlier.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b8a8ba2-5ff5-4744-b358-cf3e97ebff72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Local Outlier Factor (LOF) algorithm is an unsupervised anomaly detection method which computes the local density \\n   deviation of a given data point with respect to its neighbors. It considers as outliers the samples that have a\\n   substantially lower density than their neighbors.\\n   The LOF of a point p is the sum of the LRD of all the points in the set kNearestSet(p) * the sum of the reachDistance\\n   of all the points of the same set, to the point p , all divided by the number of items in the set, kNearestSetCount(p)\\n   , squared.\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q9\n",
    "'''The Local Outlier Factor (LOF) algorithm is an unsupervised anomaly detection method which computes the local density \n",
    "   deviation of a given data point with respect to its neighbors. It considers as outliers the samples that have a\n",
    "   substantially lower density than their neighbors.\n",
    "   The LOF of a point p is the sum of the LRD of all the points in the set kNearestSet(p) * the sum of the reachDistance\n",
    "   of all the points of the same set, to the point p , all divided by the number of items in the set, kNearestSetCount(p)\n",
    "   , squared.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "27cfc8f7-92ba-4c17-ba29-1ffa5af866a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Isolation Forest is based on the Decision Tree algorithm. It isolates the outliers by randomly selecting a feature \\n   from the given set of features and then randomly selecting a split value between the max and min values of that \\n   feature.\\n   The Isolation Forest (IForest) algorithm is a powerful and scalable algorithm for identifying outliers in your \\n   data. It uses a unique approach which focuses directly on characterizing outliers instead of normal data points.\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q10\n",
    "'''Isolation Forest is based on the Decision Tree algorithm. It isolates the outliers by randomly selecting a feature \n",
    "   from the given set of features and then randomly selecting a split value between the max and min values of that \n",
    "   feature.\n",
    "   The Isolation Forest (IForest) algorithm is a powerful and scalable algorithm for identifying outliers in your \n",
    "   data. It uses a unique approach which focuses directly on characterizing outliers instead of normal data points.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3759559-f460-48dc-bdee-1ad6b836962f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q11\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
